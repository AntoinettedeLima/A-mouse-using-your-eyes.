{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyOs6iPeugH9hhRjzmzTY/IY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AntoinettedeLima/A-mouse-using-your-eyes./blob/main/FYP_CODE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MOUNTING THE DRIVE TO LOAD THE DATA SET**"
      ],
      "metadata": {
        "id": "6M7hV5A50RI9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1crk3DeMj6t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "25ef7e20-b15d-4e27-ab8a-4704476e269d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To read and write geospatial raster data, specifically designed to handle GeoTIFF. (to open .tif files)\n",
        "!pip install rasterio\n",
        "\n",
        "#  to apply operations like erosion in the Dark Channel Prior function.\n",
        "!pip install opencv-python rasterio tensorflow\n"
      ],
      "metadata": {
        "id": "_agdkT1P2OdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "from glob import glob\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "E1I_pbat12Ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the directory where fog images are stored\n",
        "fog_data_dir = '/content/drive/MyDrive/Duweeja de Lima - FYP Folder - 20210522/Data sets/FOGG DATA'  # Update this path\n",
        "save_dir = '/content/drive/MyDrive/Duweeja de Lima - FYP Folder - 20210522/Data sets/SORTED FOG DATA'  # Update this path\n",
        "os.makedirs(save_dir, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "06-G0i_y16OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of all .tif files in the directory and map indexes to file paths\n",
        "fog_images = glob(os.path.join(fog_data_dir, '*.tif'))\n",
        "indexed_images = {}"
      ],
      "metadata": {
        "id": "9OI5LH6JEwnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract index from filename for sorting\n",
        "for img in fog_images:\n",
        "    match = re.search(r'(\\d+)', os.path.basename(img))\n",
        "    if match:\n",
        "        index = int(match.group(1))\n",
        "        indexed_images[index] = img\n",
        "\n",
        "# Sort images by index\n",
        "sorted_images = [indexed_images[index] for index in sorted(indexed_images.keys())]"
      ],
      "metadata": {
        "id": "0A2cmSuTE0kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DEFINNING NORMALIZATION AND DARK CHANNEL PRIOR FUNCTIONS**"
      ],
      "metadata": {
        "id": "-8SFGU9TE7oR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to normalize images\n",
        "def normalize_image(img):\n",
        "    return (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "# DCP function for defogging\n",
        "def dark_channel_prior(image, patch_size=15):\n",
        "    min_channel = np.min(image, axis=2)\n",
        "    dark_channel = cv2.erode(min_channel, np.ones((patch_size, patch_size)))\n",
        "    flat_dark = dark_channel.ravel()\n",
        "    sorted_indices = np.argsort(flat_dark)[::-1]\n",
        "    n_pixels = int(0.001 * len(flat_dark))\n",
        "    atmospheric_light = np.mean(image.reshape(-1, 3)[sorted_indices[:n_pixels]], axis=0)\n",
        "    transmission = 1 - 0.95 * (dark_channel / atmospheric_light.max())\n",
        "    transmission = np.clip(transmission, 0.1, 0.9)\n",
        "    result = np.empty_like(image)\n",
        "    for i in range(3):\n",
        "        result[:, :, i] = (image[:, :, i] - atmospheric_light[i]) / transmission + atmospheric_light[i]\n",
        "    return np.clip(result, 0, 255).astype(np.uint8)\n"
      ],
      "metadata": {
        "id": "qLk-gHLrFLYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROCESSING IMAGES IN BATCHES**"
      ],
      "metadata": {
        "id": "S7_dEa2-FeKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process images in batches to avoid memory overload\n",
        "def process_images_in_batches(image_paths, batch_size=50):\n",
        "    processed_images = []\n",
        "    for i in range(0, len(image_paths), batch_size):\n",
        "        batch = image_paths[i:i + batch_size]\n",
        "        batch_processed = []\n",
        "        for file_path in batch:\n",
        "            with rasterio.open(file_path) as img:\n",
        "                image_data = img.read([1, 2, 3])  # Assume RGB bands\n",
        "                image_data = np.moveaxis(image_data, 0, -1)  # Rearrange for DCP (H, W, C)\n",
        "                dcp_image = dark_channel_prior(image_data)\n",
        "                normalized_image = normalize_image(dcp_image)\n",
        "                batch_processed.append(normalized_image)\n",
        "        processed_images.extend(batch_processed)\n",
        "    return processed_images\n",
        "\n",
        "# Apply the processing function in batches\n",
        "preprocessed_images = process_images_in_batches(sorted_images, batch_size=50)\n"
      ],
      "metadata": {
        "id": "j7xeIRdhFQ7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w7f6nWYkFip4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fyvMES3_FitQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hRjmDXpzFQ-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------------------------------"
      ],
      "metadata": {
        "id": "_D-ASS6LFL46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of all .tif files in the directory\n",
        "#fog_images = glob(os.path.join(fog_data_dir, '*.tif'))\n",
        "\n",
        "# Display the number of images loaded\n",
        "#print(f\"Number of fog images: {len(fog_images)}\")\n"
      ],
      "metadata": {
        "id": "wZJJG0Pg2_ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the indexes of all images\n",
        "print(\"Indexes of fog images:\")\n",
        "for index, image_path in enumerate(fog_images):\n",
        "    print(f\"Index {index}: {os.path.basename(image_path)}\")\n"
      ],
      "metadata": {
        "id": "IESchfe93E-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract indexes from filenames\n",
        "indexes = []\n",
        "for img in fog_images:\n",
        "    # Extract numbers from filenames, assuming format 'image_<index>.tif'\n",
        "    match = re.search(r'(\\d+)', os.path.basename(img))\n",
        "    if match:\n",
        "        indexes.append(int(match.group(1)))\n",
        "\n",
        "# Sort indexes to find missing numbers\n",
        "indexes.sort()\n",
        "missing_indexes = []\n",
        "\n",
        "# Check for missing indexes in the sorted list\n",
        "for i in range(indexes[0], indexes[-1] + 1):\n",
        "    if i not in indexes:\n",
        "        missing_indexes.append(i)\n",
        "\n",
        "# Output results\n",
        "if missing_indexes:\n",
        "    print(f\"Missing indexes: {missing_indexes}\")\n",
        "else:\n",
        "    print(\"All indexes are present.\")\n"
      ],
      "metadata": {
        "id": "E3ESqpLK3es_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary to map indexes to file paths\n",
        "indexed_images = {}\n",
        "\n",
        "for img in fog_images:\n",
        "    # Extract numbers from filenames, assuming format 'image_<index>.tif'\n",
        "    match = re.search(r'(\\d+)', os.path.basename(img))\n",
        "    if match:\n",
        "        index = int(match.group(1))\n",
        "        indexed_images[index] = img\n",
        "\n",
        "# Sort images by index\n",
        "sorted_images = [indexed_images[index] for index in sorted(indexed_images.keys())]\n",
        "\n",
        "# Print the sorted list of file paths\n",
        "print(\"Sorted list of images by index:\")\n",
        "for img_path in sorted_images:\n",
        "    print(img_path)\n"
      ],
      "metadata": {
        "id": "LtibVBxv3jqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display a sample image\n",
        "def display_image(file_path):\n",
        "    with rasterio.open(file_path) as img:\n",
        "        plt.imshow(img.read(1), cmap='gray')\n",
        "        plt.title(f\"Sample Image: {os.path.basename(file_path)}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "# Display a sample image from the sorted list to inspect\n",
        "display_image(sorted_images[0])  # Show the first image in the sorted list"
      ],
      "metadata": {
        "id": "PBZjuErU3Io2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA NORMALIZATION**"
      ],
      "metadata": {
        "id": "JgkcBSZS6s9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization function\n",
        "# adjusting the pixel values of an image so that they lie within a specific range, typically between 0 and 1\n",
        "def normalize_image(img):\n",
        "    return (img - img.min()) / (img.max() - img.min())\n"
      ],
      "metadata": {
        "id": "k7uoNsQT64Bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DARC CHANNEL PRIOR FOR DEFOGGING**"
      ],
      "metadata": {
        "id": "ONvImrnt8wWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DCP function for defogging\n",
        "def dark_channel_prior(image, patch_size=15):\n",
        "    min_channel = np.min(image, axis=2)\n",
        "    dark_channel = cv2.erode(min_channel, np.ones((patch_size, patch_size)))\n",
        "    flat_dark = dark_channel.ravel()\n",
        "    sorted_indices = np.argsort(flat_dark)[::-1]\n",
        "    n_pixels = int(0.001 * len(flat_dark))\n",
        "    atmospheric_light = np.mean(image.reshape(-1, 3)[sorted_indices[:n_pixels]], axis=0)\n",
        "    transmission = 1 - 0.95 * (dark_channel / atmospheric_light.max())\n",
        "    transmission = np.clip(transmission, 0.1, 0.9)\n",
        "    result = np.empty_like(image)\n",
        "    for i in range(3):\n",
        "        result[:, :, i] = (image[:, :, i] - atmospheric_light[i]) / transmission + atmospheric_light[i]\n",
        "    return np.clip(result, 0, 255).astype(np.uint8)"
      ],
      "metadata": {
        "id": "NTE3vJpM66Wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RESIZING IMAGES**"
      ],
      "metadata": {
        "id": "nlbQddh_-Byn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize function\n",
        "def resize_images(images, target_size=(256, 256)):\n",
        "    resized_images = []\n",
        "    for img in images:\n",
        "        resized_img = cv2.resize(img, target_size, interpolation=cv2.INTER_LINEAR)\n",
        "        resized_images.append(resized_img)\n",
        "    return resized_images"
      ],
      "metadata": {
        "id": "9va47lp1-J4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**APPLYING DCP, NORMALIZATION AND RESIZING TO ALL SORTED IMAGES**"
      ],
      "metadata": {
        "id": "jLV-i6zQ-Lfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply DCP, normalization, and resizing to all sorted images\n",
        "preprocessed_images = []\n",
        "for file_path in sorted_images:\n",
        "    with rasterio.open(file_path) as img:\n",
        "        image_data = img.read([1, 2, 3])  # Assume RGB bands\n",
        "        image_data = np.moveaxis(image_data, 0, -1)  # Rearrange for DCP (H, W, C)\n",
        "        dcp_image = dark_channel_prior(image_data)\n",
        "        normalized_image = normalize_image(dcp_image)\n",
        "        preprocessed_images.append(normalized_image)\n",
        "\n",
        "# Resize all DCP-processed images\n",
        "resized_fog_images = resize_images(preprocessed_images, target_size=(256, 256))\n"
      ],
      "metadata": {
        "id": "aamvo5ta-Wc4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}